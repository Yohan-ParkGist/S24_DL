{"cells":[{"cell_type":"markdown","metadata":{"id":"l12Fft2o15eq"},"source":["# HW02\n","Deep Learning, GIST RT5101-01, 2024, Spring, (Tue/Thurs 2:30~3:45)\n","***\n","\n","### Problem1. Fully Connected Layer vs Convolution Neural Network\n","- Build your custom CNN model\n","- Check the result CNN has better result than FCN\n","- The test accuracy must bigger than 60%\n","\n","----\n","\n","### Problem2. Train Dogs and Cats data via CNN\n","- Understand the process of training the CNN model with custom dataloader.   \n","(Download URL: https://www.kaggle.com/c/dogs-vs-cats)\n","- Check the result\n","- The test accuracy must bigger than 60%\n","\n","***\n","### You can add additional code for checking your image and model.\n","### You must summit ``.ipynb`` file. Do not summit ``.py`` file.\n","---\n","\n","### How to submit your homework\n","Submit your jupyter notebook file with the filename of  *HW02_studentnumber.ipynb*  on GEL\n","\n","Ex) HW02_20222015.ipynb  \n","\n","### Submission deadline\n","2024.06.16, Sunday 23:59 (PM)\n","\n","### Plagiarism\n","We encourage you to discuss this homework with your friends or TA, but you should write your own code.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"RD1clLaR-8Dm"},"source":["***\n","***"]},{"cell_type":"markdown","metadata":{"id":"gczKrj5F4-0Z"},"source":["## Problem 1. (total 10 pt.)\n","- **Fully Connected Layer vs Convolution Neural Network**\n","- We will use cifar10 dataset.\n","- You have to compare with HW1 result and check CNN model has better result.\n","- The test accuracy of CNN model must bigger than 60%.   \n","- Reference : https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"]},{"cell_type":"markdown","metadata":{"id":"gsP6ek_hQLrf"},"source":["### Problem 1-1. (2 pt.)\n","- **Step 1**. Import package.  \n","- **Step 2**. Define device and configure hyperparameters.  \n","- **Step 3**. Download then load Cifar10 dataset to dataloader. You have to adjust transform.   "]},{"cell_type":"code","execution_count":1,"metadata":{"id":"O4odsWMnuDrq"},"outputs":[],"source":["''' Step 1 '''\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"c7yy42AoQLrg"},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# for reproducibility\n","torch.manual_seed(777)\n","if device == 'cuda':\n","    torch.cuda.manual_seed_all(777)\n","\n","lr = 1e-4\n","num_classes = 10\n","batch_size = 32\n","epochs = 20"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"rrRnBvucQLrg"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 170498071/170498071 [07:44<00:00, 367247.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data\\cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}],"source":["def dataset(is_train):\n","\n","    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5,0.5, 0.5))])\n","\n","    dataset = torchvision.datasets.CIFAR10(root='./data',train=is_train,download=True,transform=transform)\n","\n","\n","    return dataset\n","\n","train_dataset = dataset(is_train=True)\n","val_dataset = dataset(is_train=False)\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, \n","                                         shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"h6GJ_6hHQLrh"},"source":["### Problem 1-2. (5 pt.)\n","- **Step 1**. Build your CNN model.  \n","- **Step 2**. Configure optimizer and objective function.  "]},{"cell_type":"code","execution_count":4,"metadata":{"id":"ecyne8NzQLrh"},"outputs":[],"source":["''' Step 1 '''\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n","        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n","        self.fc2 = nn.Linear(512, 256)\n","        self.fc3 = nn.Linear(256, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = self.pool(F.relu(self.conv3(x)))\n","        x = x.view(-1, 128 * 4 * 4)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"ozCGI0GqQLri"},"outputs":[],"source":["''' Step 2 '''\n","model = CNN()\n","model.to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr)\n","criterion = nn.CrossEntropyLoss().to(device)"]},{"cell_type":"markdown","metadata":{"id":"qArYp1_kQLri"},"source":["### Problem 1-3. (3 pt.)\n","- **Step 1**. The method for model training\n","- **Step 2**. The method for testing model\n","- **Step 3**. Train the model and check the test results\n","- **Step 4**. Check the output after training"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"h0ipIhAjQLri"},"outputs":[],"source":["''' Step 1 '''\n","def train():\n","    for epoch in range (epochs):\n","        model.train()\n","        running_loss=0.0\n","        for inputs, labels in train_loader:\n","            optimizer.zero_grad()\n","            outputs = model(inputs.to(device))\n","            loss = criterion(outputs, labels.to(device))\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}\")"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"TxcXC-7dQLri"},"outputs":[],"source":["''' Step 2 '''\n","def test():\n","    model.eval()\n","    with torch.no_grad():\n","        total = 0.0\n","        correct = 0.0\n","        for inputs, labels in val_loader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    print(f\"Test Accuracy: {(correct/total)*100:.2f}%\")"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"qw1jc_6CQLrj"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20, Loss: 1.6649177978607759\n","Epoch 2/20, Loss: 1.3492298768028874\n","Epoch 3/20, Loss: 1.203518074861491\n","Epoch 4/20, Loss: 1.0767964644837822\n","Epoch 5/20, Loss: 0.9865622573835454\n","Epoch 6/20, Loss: 0.9063960117021587\n","Epoch 7/20, Loss: 0.8405444551299798\n","Epoch 8/20, Loss: 0.7825292828883106\n","Epoch 9/20, Loss: 0.7283496082744305\n","Epoch 10/20, Loss: 0.6759020006015982\n","Epoch 11/20, Loss: 0.627928626829054\n","Epoch 12/20, Loss: 0.5794981039073783\n","Epoch 13/20, Loss: 0.5307542046940792\n","Epoch 14/20, Loss: 0.4853514309159777\n","Epoch 15/20, Loss: 0.4378185375657359\n","Epoch 16/20, Loss: 0.3967183022375528\n","Epoch 17/20, Loss: 0.35307734803328206\n","Epoch 18/20, Loss: 0.3088200703473024\n","Epoch 19/20, Loss: 0.26942034989061525\n","Epoch 20/20, Loss: 0.2288574513562753\n"]}],"source":["''' Step 3 '''\n","train()\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"VulDjbUpQLrj"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Accuracy: 74.44%\n"]}],"source":["''' Step 4 '''\n","test()"]},{"cell_type":"markdown","metadata":{"id":"dVshAnR7QLrj"},"source":["---\n","---"]},{"cell_type":"markdown","metadata":{"id":"ZzXL1yhCQLrj"},"source":["## Problem 2. (Total 10 pt.)\n","- **Train Dogs and Cats data via CNN**\n","- **You must set the class that Dogs are 0 and Cats are 1.**\n","- Understand the process of training the CNN model with custom dataloader.\n","- Download the dataset from below.   \n","https://www.kaggle.com/c/dogs-vs-cats\n","- The test accuracy of CNN model must bigger than 60%.   "]},{"cell_type":"markdown","metadata":{"id":"H2FIGQRP5AMc"},"source":["### Problem 2-1. (4 pt.)\n","- **Step 1**. Import package.  \n","- **Step 2**. Define device and configure hyperparameters.  \n","- **Step 3**. Load **Dogs and Cats** dataset to dataloader. You have to adjust transform.  \n","**You can label dataset via images name at train folder.**"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"-V47SD_74_X2"},"outputs":[],"source":["''' Step 1 '''\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","import os\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image"]},{"cell_type":"code","execution_count":92,"metadata":{"id":"yDllJkdAQLrk"},"outputs":[],"source":["''' Step 2 '''\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# for reproducibility\n","torch.manual_seed(777)\n","if device == 'cuda':\n","    torch.cuda.manual_seed_all(777)\n","\n","lr = 1e-3\n","num_classes = 2\n","batch_size = 32\n","epochs = 20"]},{"cell_type":"code","execution_count":70,"metadata":{"id":"gi8X2HxjQLrk"},"outputs":[],"source":["''' Step 3 '''\n","\n","transform = transforms.Compose([\n","    transforms.Resize((64, 64)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","class CustomImageDataset(Dataset):\n","    def __init__(self, img_dir, transform=None):\n","        self.img_dir = img_dir\n","        self.transform = transform\n","        self.img_labels = [img for img in os.listdir(img_dir) if img.endswith(('.png', '.jpg', '.jpeg'))]\n","        \n","    def __len__(self):\n","        return len(self.img_labels)\n","\n","    def __getitem__(self, idx):\n","        img_name = os.path.join(self.img_dir, self.img_labels[idx])\n","        image = Image.open(img_name).convert(\"RGB\")\n","        \n","        if self.transform:\n","            image = self.transform(image)\n","        \n","        \n","        label = 0 if 'cat' in img_name else 1\n","        \n","        return image, label\n","\n","# Paths to train and test directories\n","train_dir = './data/train'\n","test_dir = './data/test1'\n","\n","# Create datasets\n","train_dataset = CustomImageDataset(img_dir=train_dir, transform=transform)\n","test_dataset = CustomImageDataset(img_dir=test_dir, transform=transform)\n","\n","# Create DataLoaders\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"fwU3wjwQQLrk"},"source":["### Problem 2-2. (3 pt.)\n","- **Step 1**. Build your CNN model.  \n","(It doesn't matter if you use same model at problem 1.)\n","- **Step 2**. Configure optimizer and objective function."]},{"cell_type":"code","execution_count":96,"metadata":{"id":"1_gWx7gqQLrl"},"outputs":[],"source":["''' Step 1 '''\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n","        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n","        self.fc2 = nn.Linear(512, 256)\n","        self.fc3 = nn.Linear(256, num_classes)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = self.pool(F.relu(self.conv3(x)))\n","        x = x.view(-1, 128 * 8 * 8)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","    \n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","                if m.bias is not None:\n","                    nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","                nn.init.constant_(m.bias, 0)"]},{"cell_type":"code","execution_count":100,"metadata":{"id":"RvJ3tu-qQLrl"},"outputs":[],"source":["''' Step 2 '''\n","model = CNN()\n","model.to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr)\n","criterion = nn.CrossEntropyLoss().to(device)"]},{"cell_type":"markdown","metadata":{"id":"MEXKlY8IQLrl"},"source":["### Problem 2-3. (3 pt.)\n","- **Step 1**. The method for model training\n","- **Step 2**. The method for validation model\n","- **Step 3**. Train the model and check the validation results\n","- **Step 4**. Check the test result by **ten** samples with image"]},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[],"source":["def train():\n","    for epoch in range (epochs):\n","        model.train()\n","        running_loss=0.0\n","        for inputs, labels in train_loader:\n","            optimizer.zero_grad()\n","            outputs = model(inputs.to(device))\n","            loss = criterion(outputs, labels.to(device))\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}\")"]},{"cell_type":"code","execution_count":102,"metadata":{"id":"q5JXNtXXQLrl"},"outputs":[],"source":["''' Step 2 '''\n","def test():\n","    model.eval()\n","    with torch.no_grad():\n","        total = 0.0\n","        correct = 0.0\n","        for inputs, labels in test_loader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    print(f\"Test Accuracy: {(correct/total)*100:.2f}%\")"]},{"cell_type":"code","execution_count":103,"metadata":{"id":"H3tgJ16sQLrl"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20, Loss: 0.5729589254578666\n","Epoch 2/20, Loss: 0.4546574332258281\n","Epoch 3/20, Loss: 0.3727748208033764\n","Epoch 4/20, Loss: 0.30781736307779844\n","Epoch 5/20, Loss: 0.2410991940447284\n","Epoch 6/20, Loss: 0.17159400896771865\n","Epoch 7/20, Loss: 0.1103549790952731\n","Epoch 8/20, Loss: 0.07368354531227732\n","Epoch 9/20, Loss: 0.05623959177976076\n","Epoch 10/20, Loss: 0.042506265271630116\n","Epoch 11/20, Loss: 0.03633941871528042\n","Epoch 12/20, Loss: 0.04141382767995166\n","Epoch 13/20, Loss: 0.0272892367213357\n","Epoch 14/20, Loss: 0.026352161336512196\n","Epoch 15/20, Loss: 0.027849032139021006\n","Epoch 16/20, Loss: 0.026855479767730468\n","Epoch 17/20, Loss: 0.02462334303168168\n","Epoch 18/20, Loss: 0.02583025303811783\n","Epoch 19/20, Loss: 0.02029251860254762\n","Epoch 20/20, Loss: 0.0231042836820231\n"]}],"source":["''' Step 3 '''\n","train()\n"]},{"cell_type":"code","execution_count":104,"metadata":{"id":"RRmeJxTgQLrl"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Accuracy: 49.83%\n"]}],"source":["''' Step 4 '''\n","test()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"DL","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"}},"nbformat":4,"nbformat_minor":0}
